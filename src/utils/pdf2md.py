import os
import re
from pathlib import Path
import pymupdf.layout
import pymupdf4llm


def merge_if_likely_error(match):
    # Get all captured groups, filter out None values
    groups = [g for g in match.groups() if g is not None]
    merged = ''.join(groups)
    
    # If the merged word is very short (< 4 chars), it might be intentional
    # Keep the original unless it looks like a split word
    original = match.group(0)
    
    # Heuristic: if removing spaces creates a word-like pattern, merge it
    # This is a simple approach - you may need to refine based on your data
    if len(merged) >= 4:
        return merged
    
    return original


def fix_errant_spaces(text):
    """
    Remove errant spaces within words that were likely caused by PDF extraction.
    Preserves intentional spaces between words.
    """
    # Pattern: matches single letters or short fragments separated by single spaces
    # but only when they're not at word boundaries
    # This looks for: letter(s) + space + 1-2 letters + space pattern
    pattern = r'\b(\w{1,3})\s+(\w{1,3})\s+(\w{1,3})\b|\b(\w{1,3})\s+(\w{1,2})\b'
    
    # Apply the pattern
    fixed = re.sub(pattern, merge_if_likely_error, text)
    
    return fixed


def fix_errant_spaces_aggressive(text):
    """
    More aggressive approach: removes spaces between parts of words
    by looking for common split patterns, while preserving legitimate short words.
    """
    # Common legitimate 1-3 character English words that should NOT be merged
    SHORT_WORDS = {
        'a', 'an', 'as', 'at', 'am',
        'be', 'by', 'do', 'go', 'he', 'hi', 'if', 'in', 'is', 'it', 'me', 
        'my', 'no', 'of', 'on', 'or', 'ox', 'so', 'to', 'up', 'us', 'we',
        'and', 'are', 'but', 'can', 'car', 'cat', 'cow', 'day', 'did', 'dog',
        'eat', 'end', 'far', 'few', 'for', 'get', 'got', 'had', 'has', 'her',
        'him', 'his', 'hot', 'how', 'its', 'let', 'may', 'new', 'not', 'now',
        'odd', 'off', 'old', 'one', 'our', 'out', 'own', 'per', 'put', 'ran',
        'red', 'run', 'saw', 'say', 'see', 'set', 'she', 'sir', 'sit', 'six',
        'ten', 'the', 'too', 'top', 'try', 'two', 'use', 'was', 'way', 'who',
        'why', 'win', 'yes', 'yet', 'you', 'via', 'per', 'etc', 'age', 'add'
    }
    
    # Split on word boundaries
    words = text.split()
    fixed_words = []
    i = 0
    
    while i < len(words):
        current = words[i]
        current_clean = current.lower().strip('.,;:!?()"\'')
        
        # Look ahead to see if next 1-3 words should be merged
        if i < len(words) - 1:
            # Check if current word is very short (1-3 chars) AND not a known word
            if len(current_clean) <= 3 and current_clean not in SHORT_WORDS:
                merged = current
                j = i + 1
                
                # Keep merging while we have short fragments that aren't known words
                while j < len(words) and j < i + 4:
                    next_word = words[j]
                    next_clean = next_word.lower().strip('.,;:!?()"\'')
                    
                    # Stop if we hit a known short word
                    if next_clean in SHORT_WORDS:
                        break
                    
                    # Stop if the word is longer than 3 chars (likely legitimate)
                    if len(next_clean) > 3:
                        # But merge this one last long fragment if pattern suggests split word
                        merged += next_word
                        j += 1
                        break
                    
                    merged += next_word
                    j += 1
                
                # If we merged something and result looks like a word
                if j > i + 1 and len(merged.strip('.,;:!?()"\'')) >= 4:
                    fixed_words.append(merged)
                    i = j
                    continue
        
        fixed_words.append(current)
        i += 1
    
    return ' '.join(fixed_words)


def pdf_to_markdown(pdf_path: Path|str, output_path: Path|str) -> None:
    """Convert a PDF file to markdown while preserving page numbers."""
    doc = pymupdf.open(pdf_path)
    md_text = pymupdf4llm.to_markdown(doc, page_chunks=True, write_images=False, header=False)
    Path(output_path).write_bytes(md_text.encode())
    return


def strip_lines(md_path: str) -> None:
    """ Clean up the generated markdown file by removing unwanted spaces and lines. """
    with open(md_path, 'r', encoding='utf-8') as file:
        lines = file.readlines()

    cleaned_lines = []
    for line in lines:
        # Remove lines that are just spaces or unwanted patterns
        if line.strip() and "Generated by pymupdf4llm" not in line:
            cleaned_lines.append(line.rstrip() + '\n')

    with open(md_path, 'w', encoding='utf-8') as file:
        file.writelines(cleaned_lines)


def fix_markdown_tables(content, column_names=None):
    """
    Fix improperly formatted markdown tables where citations are in the header
    and content is in columns with empty first column cells.
    
    Args:
        content: The markdown content to fix
        column_names: Optional list of column names. If None or shorter than 
                     the number of columns, remaining columns will be empty.
    """
    lines = content.split('\n')
    result = []
    i = 0
    
    while i < len(lines):
        line = lines[i]
        
        # Check if this is a malformed table header with multiple citations
        if '|' in line and i + 1 < len(lines) and '|---' in lines[i + 1]:
            # Detect number of columns from separator line
            separator = lines[i + 1]
            num_columns = separator.count('|') - 1
            
            # Extract citations from header
            header_parts = [p.strip() for p in line.split('|') if p.strip()]
            
            # Check if first cell contains multiple citations (space-separated)
            if header_parts and any(year in header_parts[0] for year in ['(20', '(19']):
                citations = re.split(r'\s+(?=[A-Z])', header_parts[0])
                
                # Build header with provided or empty column names
                if column_names:
                    headers = column_names[:num_columns]
                    # Pad with empty strings if not enough names provided
                    headers += [''] * (num_columns - len(headers))
                else:
                    headers = [''] * num_columns
                
                # Add proper header
                result.append('| ' + ' | '.join(headers) + ' |')
                result.append('|' + '---|' * num_columns)
                
                # Skip the separator line
                i += 2
                
                # Process data rows
                citation_idx = 0
                while i < len(lines) and lines[i].startswith('|'):
                    parts = [p.strip() for p in lines[i].split('|')]
                    # Filter out empty strings from start/end
                    parts = [p for p in parts if p or parts.index(p) not in [0, len(parts)-1]]
                    
                    # Reconstruct row with citation
                    if citation_idx < len(citations):
                        row_data = [citations[citation_idx]]
                        # Add remaining columns from the original row
                        for j in range(1, num_columns):
                            if j < len(parts) + 1:
                                row_data.append(parts[j-1] if j-1 < len(parts) else '')
                            else:
                                row_data.append('')
                        result.append('| ' + ' | '.join(row_data) + ' |')
                        citation_idx += 1
                    i += 1
                continue
        
        result.append(line)
        i += 1
    
    return '\n'.join(result)


def process_markdown_file(input_file: Path|str, output_file: Path|str):
    """Process a markdown file to fix errant spaces."""

    with open(input_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    fixed_content = fix_markdown_tables(content)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(fixed_content)
    
    print(f"Processed {input_file} -> {output_file}")


def process_folder(input_folder: Path|str, output_folder: Path|str) -> None:
    """Process all PDF files in a folder and convert them to markdown."""
    input_path = Path(input_folder)
    output_path = Path(output_folder)
    output_path.mkdir(parents=True, exist_ok=True)
    
    pdf_files = list(input_path.glob('*.pdf'))
    
    if not pdf_files:
        print(f"No PDF files found in {input_folder}")
        return
    
    for pdf_file in pdf_files:
        md_filename = pdf_file.stem + '.md'

        # save markdown file in a directory named after the pdf
        output_path = os.path.join(output_folder, pdf_file.stem)
        Path(output_path).mkdir(parents=True, exist_ok=True)
        md_filepath = os.path.join(output_path, md_filename)
        
        print(f"Converting {pdf_file.name} to markdown...")
        try:
            pdf_to_markdown(str(pdf_file), str(md_filepath))
            print(f"✓ Created {md_filename}")

            print("Cleaning up markdown...")
            # strip_lines(str(md_filepath))
            # process_markdown_file(str(md_filepath), str(md_filepath))

        except Exception as e:
            print(f"✗ Error processing {pdf_file.name}: {e}")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Convert PDFs in a folder to cleaned markdown files.")
    parser.add_argument(
        "input", "-i",
        type=str,
        required=False,
        default="../../data/raw/pdfs",
        help="Path to the PDF file or folder containing PDF files."
    )
    parser.add_argument(
        "output", "-o",
        type=str,
        required=False,
        default="../../data/raw/pdfs/markdown_output",
        help="Name of output file or path to the folder where outputs should be saved."
    )

    args = parser.parse_args()
    INPUT = Path(args.input_folder)
    OUTPUT = Path(args.output_folder)

    if INPUT.is_dir() and OUTPUT.is_dir():
        process_folder(INPUT, OUTPUT)
    elif INPUT.is_file() and OUTPUT.is_file():
        process_markdown_file(INPUT, OUTPUT)
    elif INPUT.is_file() and OUTPUT.is_dir():
        output_file = OUTPUT / (INPUT.stem + '.md')
        process_markdown_file(INPUT, output_file)
    else:
        print("Input configuration not recognized. Please provide valid file or directory paths.")
